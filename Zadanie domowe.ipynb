{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inżynieria lingwistyczna\n",
    "Ten notebook jest oceniany półautomatycznie. Nie twórz ani nie usuwaj komórek - struktura notebooka musi zostać zachowana. Odpowiedź wypełnij tam gdzie jest na to wskazane miejsce - odpowiedzi w innych miejscach nie będą sprawdzane (nie są widoczne dla sprawdzającego w systemie).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 1 - tokenizacja (12 pkt)\n",
    "\n",
    "Jedną z nowoczesnych technik tokenizacji jest BPE - byte-pair encoding [1]. Technika ta polega na podzielenie słów na częste podsłowa (morfemy). W przeciwieństwie do podejść lingwistycznych, wymagających reguł tworzenia morfemów, BPE wyznacza je automatycznie poprzez wyznaczenie najczęstszych przylegających do siebie sekwencji znaków które występują obok siebie.\n",
    "\n",
    "Algorytm przebiega w następujących krokach.\n",
    "1. Podziel wszystkie słowa na symbole (początkowo pojedyncze znaki)\n",
    "2. Wyznacz najczęściej występującą obok siebie parę symboli \n",
    "3. Stwórz nowy symbol będący konkatenacją dwóch najczęstszych symboli.\n",
    "\n",
    "Uwaga 1: każde słowo zakończone jest specjalnym symbolem końca wyrazu.\n",
    "\n",
    "Uwaga 2: tworzenie nowego symbolu nie powoduje usuniecie starego tj. zawsze jednym z możliwych symboli jest pojedynczy znak, ale jeśli można to stosujemy symbol dłuższy.\n",
    "\n",
    "Przykład: korpus w którym występuje ,,ala'' 5 razy i ,,mama 10 razy''\n",
    "1. Dzielimy słowa na symbole ,,a l a END'' ,,m a m a END''  gdzie END jest symbolem końca wyrazu.\n",
    "2. Najczęstsza para obok siebie to ,,m a'' (20) razy\n",
    "3. Nowy symbol ,,ma''\n",
    "4. Nowy podział ,,a l a END'' ,,ma ma END''\n",
    "5. Najczęstsza para ,,ma ma'' (10) razy\n",
    "6. Nowy symbol ,,mama''\n",
    "7. Nowy podział ,,a l a END'' ,,mama END''\n",
    "8. itd.\n",
    "\n",
    "W pliku ,,brown_clusters.tsv'' pierwsza kolumna to identyfikator skupienia (nie używamy w tym zadaniu), druga kolumna to wyrazy, a trzecia to ich liczności w pewnym korpusie tweetów. Zaimplementuj technike BPE na tych słowach.\n",
    "\n",
    "Zaimplementuj algorytm BPE wykonujący `number_of_iterations` iteracji (łączeń symboli).\n",
    "\n",
    "[1] Sennrich, R., Haddow, B., and Birch, A. (2016). Neural machine translation of rare words with subword units. In ACL 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ff3b90528fdb50de90c5c946c157e21",
     "grade": false,
     "grade_id": "cell-93d78a28d4e25cbc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "brown_df = pd.read_csv('brown_clusters.tsv', sep='\\t', header=0, names=['cluster', 'word', 'count'])\n",
    "\n",
    "END_SYMBOL = 'END'\n",
    "number_of_iterations = 10\n",
    "\n",
    "\n",
    "def concatenate_words(splitted_word, first_elem, second_elem, concatenated):\n",
    "    # Preapre output\n",
    "    result = list()\n",
    "    \n",
    "    # Last seen element\n",
    "    last_seen_elem = None\n",
    "    \n",
    "    for elem in splitted_word:\n",
    "        if last_seen_elem is not None:\n",
    "            # We must check both elements\n",
    "            if last_seen_elem == first_elem and elem == second_elem:\n",
    "                # Add concatenated word to result\n",
    "                result.append(concatenated)\n",
    "                \n",
    "                # Clear last element to prevent duplications in replacement\n",
    "                last_seen_elem = None\n",
    "                \n",
    "                # Check next element\n",
    "                continue\n",
    "            else:\n",
    "                # Store previous element\n",
    "                result.append(last_seen_elem)\n",
    "            \n",
    "        # Update last seen element\n",
    "        last_seen_elem = elem\n",
    "        \n",
    "    # Add last element if not paired\n",
    "    if last_seen_elem is not None:\n",
    "        result.append(last_seen_elem)\n",
    "        \n",
    "    # Return joined list\n",
    "    return result\n",
    "\n",
    "\n",
    "def output(df):\n",
    "    \"\"\"\n",
    "    Generate output as list of words, each with <END> tag\n",
    "    \"\"\"\n",
    "    return df['word'].apply(lambda word: ' '.join(word) + ' ' + END_SYMBOL).tolist()\n",
    "    \n",
    "\n",
    "def preform_bpe(brown_df, number_of_iterations):\n",
    "    \"\"\"\n",
    "    Funkcja przyjmuje ramkę w formacie analogicznym do obiektu brown_df (wczytany wyżej)\n",
    "     oraz liczbę iteracji.\n",
    "    Wyjściem funkcji powinna być lista słów z poszczególnymi tokenami/symbolami oddzielonymi spacją.\n",
    "    Za znak końca wyrazu przyjmij END. \n",
    "    \"\"\"\n",
    "    # Copy dataframe\n",
    "    df = brown_df.copy()\n",
    "    \n",
    "    # Split each character\n",
    "    df['word'] = df['word'].astype(str).apply(lambda word: list(word))\n",
    "    \n",
    "    # Do it n-times\n",
    "    for _iteration in range(number_of_iterations):\n",
    "        # Vocabulary counter - we will use it to find the best pair\n",
    "        vocabulary = Counter()\n",
    "\n",
    "        # Iterate over elements in corpus\n",
    "        for row in df.itertuples():\n",
    "            last_element = None\n",
    "            for element in row.word:\n",
    "                if last_element is not None:\n",
    "                    # We already seen element - can generate new pair\n",
    "                    vocabulary[(last_element, element)] += row.count\n",
    "\n",
    "                # Update last seen element\n",
    "                last_element = element\n",
    "            \n",
    "        # Now we must ensure at least one pair found\n",
    "        if not vocabulary:\n",
    "            return output(df)\n",
    "\n",
    "        # We can find maximum element\n",
    "        ((first_elem, second_elem), cardinality) = vocabulary.most_common(1)[0]\n",
    "        concatenated = first_elem + second_elem\n",
    "        print(first_elem + ' AND ' + second_elem + ' ====> ' + concatenated)\n",
    "    \n",
    "        # Update words - join group \n",
    "        df['word'] = df['word'].apply(concatenate_words, args = (first_elem, second_elem, concatenated))\n",
    "    \n",
    "    # Return dataframe\n",
    "    return output(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test implementacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfff70f711bf389f0f1cd969e7c3a413",
     "grade": true,
     "grade_id": "cell-7e952fa8dcd136fe",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m AND a ====> ma\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_list_equal\n",
    "data = {'cluster': range(2), 'word':['ala', 'mama'], 'count': [5,10]}\n",
    "df = pd.DataFrame (data, columns = ['cluster', 'word', 'count'])\n",
    "vocab = preform_bpe(df, 1)\n",
    "assert_list_equal(vocab, ['a l a END', 'ma ma END'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spraw aby Twoja implementacja wypisywała kolejne łączone ze sobą symbole i uruchom Twoją funkcję na np. 50 iteracji, obserwując jakie tokeny są tworzone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i AND n ====> in\n",
      "t AND h ====> th\n",
      "a AND n ====> an\n",
      "e AND r ====> er\n",
      "o AND n ====> on\n",
      "o AND u ====> ou\n",
      "r AND e ====> re\n",
      ". AND . ====> ..\n",
      "a AND t ====> at\n",
      "t AND o ====> to\n",
      "in AND g ====> ing\n",
      "i AND t ====> it\n",
      "th AND e ====> the\n",
      "s AND t ====> st\n",
      "< AND @ ====> <@\n",
      "<@ AND M ====> <@M\n",
      "<@M AND E ====> <@ME\n",
      "<@ME AND N ====> <@MEN\n",
      "<@MEN AND T ====> <@MENT\n",
      "<@MENT AND I ====> <@MENTI\n",
      "<@MENTI AND O ====> <@MENTIO\n",
      "<@MENTIO AND N ====> <@MENTION\n",
      "<@MENTION AND > ====> <@MENTION>\n",
      "o AND r ====> or\n",
      "m AND e ====> me\n",
      "l AND l ====> ll\n",
      "i AND s ====> is\n",
      "e AND n ====> en\n",
      "a AND r ====> ar\n",
      "l AND e ====> le\n",
      "y AND ou ====> you\n",
      "o AND w ====> ow\n",
      "h AND a ====> ha\n",
      "c AND o ====> co\n",
      "e AND d ====> ed\n",
      "a AND y ====> ay\n",
      "e AND s ====> es\n",
      "< AND U ====> <U\n",
      "<U AND R ====> <UR\n",
      "<UR AND L ====> <URL\n",
      "<URL AND - ====> <URL-\n",
      "an AND d ====> and\n",
      "c AND h ====> ch\n",
      "a AND s ====> as\n",
      "l AND o ====> lo\n",
      "b AND e ====> be\n",
      "v AND e ====> ve\n",
      "a AND l ====> al\n",
      "o AND f ====> of\n",
      "w AND h ====> wh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\\\ i END',\n",
       " '/ i / END',\n",
       " 'to d ay - i END',\n",
       " 'n ow i END',\n",
       " '# you e v er END',\n",
       " 'i f in a ll y END',\n",
       " '「 i END',\n",
       " '- i - END',\n",
       " 'in e v a END',\n",
       " '» i END',\n",
       " 'wh at t ay a END',\n",
       " 'i i i i i i i i i i END',\n",
       " '\\ue6d1 END',\n",
       " 'i k in d a END',\n",
       " 'lo l - i END',\n",
       " 'i a c t u a ll y END',\n",
       " 'w a d d y a END',\n",
       " '# as l on g as you END',\n",
       " 'd o you END',\n",
       " '\\u200e \\u200b i END',\n",
       " 'i ̇ END',\n",
       " 'ï END',\n",
       " '# lo l at g i r l s wh o END',\n",
       " '# r t i f you END',\n",
       " 'i j st END',\n",
       " '« i END',\n",
       " '• i END',\n",
       " 'wh o d a END',\n",
       " 'w ha d y a END',\n",
       " ') i END',\n",
       " '+ i END',\n",
       " '# you r f a c e m a k es me END',\n",
       " 'i i i i i i i i END',\n",
       " '` i END',\n",
       " 'i i i i i i i END',\n",
       " 'i al re a d y END',\n",
       " '_ i END',\n",
       " '# you m a k e me END',\n",
       " '* i END',\n",
       " '| i END',\n",
       " '# u r b o y f r i en d e v er END',\n",
       " 'wh en i END',\n",
       " 'ι END',\n",
       " \"d on ' t c ha END\",\n",
       " \"wh o ' d a END\",\n",
       " 'd you END',\n",
       " 'w ha d d ay a END',\n",
       " 'i on l y END',\n",
       " 'i j u s s END',\n",
       " 'i al w ay s END',\n",
       " 'i i i i i END',\n",
       " 'd on c ha END',\n",
       " '( i END',\n",
       " \"d ' y a END\",\n",
       " 'ı END',\n",
       " '# u e v er END',\n",
       " 'in e v er END',\n",
       " 'i - i END',\n",
       " 'i j u s END',\n",
       " '/ / i END',\n",
       " 'i st i ll END',\n",
       " 'w ha d d y a END',\n",
       " \"d ' you END\",\n",
       " 'i re a ll y END',\n",
       " 'd on t c ha END',\n",
       " 'i j u st END',\n",
       " 'i END',\n",
       " '- i END',\n",
       " 'i you END',\n",
       " '# in n ow ay s ha p e or f or m END',\n",
       " '( you END',\n",
       " '/ / w e END',\n",
       " '/ / u END',\n",
       " '# me n m ar r y w o me n th at END',\n",
       " '/ w e END',\n",
       " 's e l f - ed u c at i on END',\n",
       " '# re al g r and m as END',\n",
       " '/ you END',\n",
       " '# s h ou t ou t to g i r l s wh o END',\n",
       " '# b o y s wh o END',\n",
       " 'i / w e END',\n",
       " '# s h ou t ou t to the g u y s th at END',\n",
       " '/ / you END',\n",
       " '# i lo ve p e o p le th at END',\n",
       " '# n o t a ll b l a c k p e o p le END',\n",
       " '# i c an t st and p e o p le th at END',\n",
       " '# s h ou t ou t to the g i r l s th at END',\n",
       " '- the y END',\n",
       " '- w e END',\n",
       " '# h ow m an y p e o p le END',\n",
       " '- you END',\n",
       " 'w e END',\n",
       " '# a q u ar i an s END',\n",
       " 't the y END',\n",
       " 'th w y END',\n",
       " 'g u i l d en st er n END',\n",
       " \"d ' u END\",\n",
       " '# i h at e m a le s wh o END',\n",
       " 't e h y END',\n",
       " 'th r y END',\n",
       " 'i f you END',\n",
       " '# h ou s e h i p p o s END',\n",
       " 'the u END',\n",
       " 'the e y END',\n",
       " '# i h at e f e m a le s wh o END',\n",
       " 'the y y END',\n",
       " 'the y END',\n",
       " 'v i o le t s END',\n",
       " 'e h o END',\n",
       " 'wh o ’ d END',\n",
       " 'wh o t f END',\n",
       " 'wh o ’ ve END',\n",
       " 'wh o d END',\n",
       " '<URL- re al . co m > END',\n",
       " '# i l i k e p e o p le wh o END',\n",
       " '- wh o END',\n",
       " 'wh 0 END',\n",
       " 'wh u END',\n",
       " 'wh o END',\n",
       " \"wh o ' ve END\",\n",
       " 's s h e END',\n",
       " 's er - u e b er w a ch er END',\n",
       " 's h h e END',\n",
       " 't e st a st er is k END',\n",
       " '# m y d u m b as s END',\n",
       " 's j e END',\n",
       " 't a ch o m a st er END',\n",
       " 'i al m o st END',\n",
       " 'i d on e END',\n",
       " '# wh at i f i END',\n",
       " 'h e / s h e / it END',\n",
       " '$ h e END',\n",
       " '# wh at i f g o d END',\n",
       " '# i h e ar d ch u c k n or r is END',\n",
       " '# f m h 2 0 1 1 END',\n",
       " '# i h e ar d b ow w ow END',\n",
       " 'b l d _ 6 0 0 _ k wh END',\n",
       " 'b l d _ 6 5 0 _ k wh END',\n",
       " 's h e e e END',\n",
       " '# f m 2 0 1 1 END',\n",
       " '- s h e END',\n",
       " '- h e END',\n",
       " 's / h e END',\n",
       " 's h e / h e END',\n",
       " '- it END',\n",
       " 's h e e END',\n",
       " 'h e / s h e END',\n",
       " 'h e END',\n",
       " 's h e END',\n",
       " '<URL- i . ve > END',\n",
       " \"l ' ve END\",\n",
       " 'the y v END',\n",
       " \"you \\\\ ' ve END\",\n",
       " \"i ' be END\",\n",
       " '<URL- i h e ar t m o v i es . or g > END',\n",
       " 'i w ou l d a END',\n",
       " 'w e ` ve END',\n",
       " \"i ha v en ' t END\",\n",
       " '# i ha v en e v er END',\n",
       " \"a : i ' ve END\",\n",
       " 'w e v END',\n",
       " 'w e ´ ve END',\n",
       " \"y u ' ve END\",\n",
       " 'u ’ ve END',\n",
       " \"- i ' ve END\",\n",
       " \"th er e ' ve END\",\n",
       " \"i ' d a END\",\n",
       " '<URL- v o o m a x er . co m > END',\n",
       " \"th at ' ve END\",\n",
       " \"w e ' v END\",\n",
       " 'you ´ ve END',\n",
       " 'i ve e END',\n",
       " \"i ' d ' ve END\",\n",
       " 'you ` ve END',\n",
       " \"i \\\\ ' ve END\",\n",
       " 'you v END',\n",
       " \"you ' v END\",\n",
       " '# n e v er ha ve i e v er END',\n",
       " \"u ' v END\",\n",
       " '<URL- n a u g h t y d o g . co m > END',\n",
       " 'i ha v en t END',\n",
       " \"i v ' e END\",\n",
       " 'the y ’ ve END',\n",
       " '# ha ve you e v er END',\n",
       " 'i ´ ve END',\n",
       " 'i ` ve END',\n",
       " '# ha ve u e v er END',\n",
       " 'the y ve END',\n",
       " \"i ' v END\",\n",
       " '0 . 0 0 % END',\n",
       " 'w e ve END',\n",
       " 'u ve END',\n",
       " 'w e ’ ve END',\n",
       " \"u ' ve END\",\n",
       " 'you ’ ve END',\n",
       " 'you ve END',\n",
       " 'i ’ ve END',\n",
       " \"the y ' ve END\",\n",
       " \"i ' ve END\",\n",
       " 'i ve END',\n",
       " \"you ' ve END\",\n",
       " \"w e ' ve END\",\n",
       " 'n o o o o o o t END',\n",
       " 'n o t t t t t t t END',\n",
       " 'n o h t END',\n",
       " 'you ha ve END',\n",
       " '/ n o t / END',\n",
       " 'n o it END',\n",
       " '- n o t - END',\n",
       " 'n o t t t t t t END',\n",
       " 'n o o o o o t END',\n",
       " \"n ' t END\",\n",
       " 'n n o t END',\n",
       " 'n a h t END',\n",
       " '_ n o t _ END',\n",
       " 'd es er v ed l y END',\n",
       " 'n o t t t t t END',\n",
       " 'n o o o o t END',\n",
       " 'n o t - END',\n",
       " 'n o o o t END',\n",
       " 'n o o t END',\n",
       " 'n to END',\n",
       " 'n o t t t t END',\n",
       " 'n o t t t END',\n",
       " 'r i g h t f u ll y END',\n",
       " 'n a w t END',\n",
       " 'n 0 t END',\n",
       " 'n o t t END',\n",
       " 'n o t END',\n",
       " 'n t END',\n",
       " 'g o t t n END',\n",
       " 'b 3 3 n END',\n",
       " 'be e e e e en END',\n",
       " 'g o t t on END',\n",
       " 's u c c es s f u l y END',\n",
       " 'be e e e en END',\n",
       " 'be en n END',\n",
       " 'u n d er g on e END',\n",
       " 'be e e en END',\n",
       " 'be e en END',\n",
       " 'be en END',\n",
       " 'g o t t en END',\n",
       " 'j u x t END',\n",
       " '/ / j u st END',\n",
       " 'j u st t t t t END',\n",
       " 'j x t END',\n",
       " '# s p or c le END',\n",
       " 'j st t END',\n",
       " 'j u r t END',\n",
       " 'j y s END',\n",
       " '/ j u st END',\n",
       " '- j u s END',\n",
       " 'j y st END',\n",
       " 'd d e u be l END',\n",
       " 'j u st t t t END',\n",
       " 'j u s s s st END',\n",
       " 'j u $ t END',\n",
       " 'j u u s END',\n",
       " 'j s st END',\n",
       " 'j u u u u u st END',\n",
       " 'k u st END',\n",
       " 'j h u s END',\n",
       " 'j u s s s s END',\n",
       " 'j h u s s END',\n",
       " 'j u st s END',\n",
       " 'j u s s st END',\n",
       " 'j u s x END',\n",
       " 'j u x x END',\n",
       " 'j z t END',\n",
       " 'j u z z END',\n",
       " 'j u d t END',\n",
       " '<URL- w o o . l y > END',\n",
       " 'j u h s END',\n",
       " 'j u u u u st END',\n",
       " 'j j u st END',\n",
       " 'j u z t END',\n",
       " 'j u st t t END',\n",
       " 'j u st ed END',\n",
       " 'j u s r END',\n",
       " 'j u u u st END',\n",
       " 'j u t s END',\n",
       " 'j u s y END',\n",
       " 'j u u st END',\n",
       " 'j u at END',\n",
       " 'j u s z END',\n",
       " '# j u st END',\n",
       " 'j s s END',\n",
       " 'j u s s s END',\n",
       " '<URL- b u y t t er . co m > END',\n",
       " 'j u s st END',\n",
       " 'j z END',\n",
       " '- j u st END',\n",
       " '# d on t a c t l i k e you n e v er END',\n",
       " 'j u t END',\n",
       " 'j u st t END',\n",
       " 'j u x END',\n",
       " 'j s u t END',\n",
       " 'j u z END',\n",
       " 'j st END',\n",
       " 'j u s s END',\n",
       " 'j u st END',\n",
       " 'j u s END',\n",
       " \"a in \\\\ ' t END\",\n",
       " 'a in ´ t END',\n",
       " \"a ' in t END\",\n",
       " 'a it n END',\n",
       " 'a in y END',\n",
       " 'w u s z END',\n",
       " 'ay n t END',\n",
       " 'a in n t END',\n",
       " 'i an t END',\n",
       " \"an ' t END\",\n",
       " 'a in e END',\n",
       " 'a in ` t END',\n",
       " 'a in n END',\n",
       " 'a in t t END',\n",
       " 'a i in t END',\n",
       " 'i a in t END',\n",
       " 'a in ’ t END',\n",
       " 'an it END',\n",
       " 'a in END',\n",
       " 'a in t END',\n",
       " \"a in ' t END\",\n",
       " 's h ou d a END',\n",
       " 's h ou l d n a END',\n",
       " 's h ou l a END',\n",
       " \"w ou l d n ' t ' ve END\",\n",
       " \"s h ou l d n ' t ' ve END\",\n",
       " 's h ou l d v END',\n",
       " \"s h u d ' ve END\",\n",
       " 'h an t END',\n",
       " \"ha v ' n t END\",\n",
       " 'c l d a END',\n",
       " 'w l d ve END',\n",
       " \"s h ou l d ' a END\",\n",
       " 'w ou l d a a END',\n",
       " 's h ou l d d a END',\n",
       " 'w u l d ve END',\n",
       " \"w u d ' ve END\",\n",
       " 'w ou l d d a END',\n",
       " 's h u l d ve END',\n",
       " 's h ou l d a a END',\n",
       " \"ha ve ' t END\",\n",
       " 'c ou l d ’ ve END',\n",
       " 'ha v en t t END',\n",
       " 's h l d ve END',\n",
       " 'c u d ve END',\n",
       " \"m ay ' ve END\",\n",
       " \"h v n ' t END\",\n",
       " 'w ou l d ’ ve END',\n",
       " 'a v n t END',\n",
       " 'w l d a END',\n",
       " 's h ou l d ’ ve END',\n",
       " 'c u l d a END',\n",
       " 'ha v en ´ t END',\n",
       " 's h l d a END',\n",
       " 'm i g h t ve END',\n",
       " 'ha v en ` t END',\n",
       " 'ha d n ’ t END',\n",
       " '# g lo c al u r b an END',\n",
       " 'h v en t END',\n",
       " 's h u d ve END',\n",
       " 'w u d ve END',\n",
       " \"ha ve ' n t END\",\n",
       " 'c u d d a END',\n",
       " 'm i g h t a END',\n",
       " 'w u l d a END',\n",
       " 's h u l d a END',\n",
       " 'w u d d a END',\n",
       " 's h u d d a END',\n",
       " 'w u d a END',\n",
       " 's h u d a END',\n",
       " 'm u st ve END',\n",
       " 'h v n t END',\n",
       " \"m i g h t ' ve END\",\n",
       " 'ha d n t END',\n",
       " \"ha v n ' t END\",\n",
       " 'ha v en ’ t END',\n",
       " 'c ou l d ve END',\n",
       " 'm u st a END',\n",
       " \"m u st ' ve END\",\n",
       " 'w ou l d ve END',\n",
       " 's h ou l d ve END',\n",
       " 'ha v n t END',\n",
       " 'c ou l d a END',\n",
       " \"c ou l d ' ve END\",\n",
       " 'w ou l d a END',\n",
       " \"ha d n ' t END\",\n",
       " \"s h ou l d ' ve END\",\n",
       " \"w ou l d ' ve END\",\n",
       " 's h ou l d a END',\n",
       " \"ha v en ' t END\",\n",
       " 'ha v en t END',\n",
       " 'n e v v a END',\n",
       " 'n e e e e v er END',\n",
       " 'n e ve t END',\n",
       " 'n e e e v er END',\n",
       " 'en v er END',\n",
       " 'n er v er END',\n",
       " 'n e e v er END',\n",
       " 'n e v a a a END',\n",
       " 'be v er END',\n",
       " '# in e v er END',\n",
       " 'g l a d y END',\n",
       " 'n e ve er END',\n",
       " '- n e v er END',\n",
       " \"n e ' er END\",\n",
       " 'le t c ha END',\n",
       " 'le t ch u END',\n",
       " 'n e v er r r r END',\n",
       " 'n v a END',\n",
       " 'n e v a h END',\n",
       " 'n e v a a END',\n",
       " 'n e v er r r END',\n",
       " 'n v er END',\n",
       " 'n e v er r END',\n",
       " '# n e v er END',\n",
       " 'n e v r END',\n",
       " 'g l a d l y END',\n",
       " 'n v r END',\n",
       " 'n e v er END',\n",
       " 'n e v a END',\n",
       " 'e v u r END',\n",
       " 'e v a a a a a END',\n",
       " 'e ve a END',\n",
       " 'e ve e e er END',\n",
       " 'e v er r r r r r r r r END',\n",
       " 'e v er r r r r r r r END',\n",
       " 'e ve e er END',\n",
       " 'e v a a a a END',\n",
       " 'e ve er END',\n",
       " 'n e v ar END',\n",
       " 'e v er r r r r r r END',\n",
       " 'e v a a a END',\n",
       " 'e v a a END',\n",
       " 'e v er r r r r r END',\n",
       " 'e v er r r r r END',\n",
       " 'e v a h END',\n",
       " 'e v er r r r END',\n",
       " 'e v er r END',\n",
       " 'e v er r r END',\n",
       " 'e v r END',\n",
       " 'e v ar END',\n",
       " 'e v a END',\n",
       " 'e v er END',\n",
       " 'on le END',\n",
       " 'in l y END',\n",
       " 'on le e END',\n",
       " 'on l u END',\n",
       " 'on y l END',\n",
       " 'on ll y END',\n",
       " 'on l t END',\n",
       " 'on l y y y END',\n",
       " 'o l n y END',\n",
       " '- on l y END',\n",
       " '0 n l y END',\n",
       " 'on l i i END',\n",
       " 'on y END',\n",
       " 'on l y y END',\n",
       " 'on l y END',\n",
       " 'on l i END',\n",
       " 'g e t 2 END',\n",
       " 'n e c c es ar i l y END',\n",
       " 'n e c c es s ar i l y END',\n",
       " 'e e e m END',\n",
       " 'e v er n END',\n",
       " 'n e v en END',\n",
       " 'le t e m END',\n",
       " 'e v en n n END',\n",
       " 'e ve b END',\n",
       " 'e e en END',\n",
       " 'e ve m END',\n",
       " 'e ve en END',\n",
       " '<URL- g t p 1 2 3 . co m > END',\n",
       " '- e v en END',\n",
       " \"1 0 x ' s END\",\n",
       " \"m a k e ' e m END\",\n",
       " \"le t ' e m END\",\n",
       " 'e v en n END',\n",
       " 'e e m END',\n",
       " 'e v n END',\n",
       " 'e v en END',\n",
       " 'n e c es s ar i l y END',\n",
       " 're e e e e e e a ll y END',\n",
       " 're a a al y END',\n",
       " 're a ll ll ll ll ll y END',\n",
       " 'r l i END',\n",
       " 're a ll i e END',\n",
       " 're a ll ll l y y y END',\n",
       " 're e l i END',\n",
       " 'r 3 a ll y END',\n",
       " 're a ll ll y y END',\n",
       " 're a ll y - re a ll y END',\n",
       " 're l al y END',\n",
       " 're a ll ll y y y y END',\n",
       " 'r i ll i END',\n",
       " 're a ll y re a ll y re a ll y END',\n",
       " '- re a ll y - END',\n",
       " 're a ll y y y y y y END',\n",
       " 're a a ll y y END',\n",
       " 'e a ll y END',\n",
       " 're e e a a a ll y END',\n",
       " 're a ll y re a ll y END',\n",
       " 're e a a ll y END',\n",
       " 'r re a ll y END',\n",
       " 're a a a a ll l y END',\n",
       " 're a ll u END',\n",
       " 're a a a a a a ll y END',\n",
       " '/ re a ll y / END',\n",
       " 're al y y END',\n",
       " 're a a ll l y END',\n",
       " 're a ll ll ll ll l y END',\n",
       " 're a ll ll y y y END',\n",
       " 're a a a ll l y END',\n",
       " 'w e a ll y END',\n",
       " 're e e e e e a ll y END',\n",
       " 're a ll l y y y y END',\n",
       " 're ll i END',\n",
       " 'g en u in l y END',\n",
       " 're a ll t END',\n",
       " 're a ll i i END',\n",
       " 're a ll l y y END',\n",
       " 're a al y END',\n",
       " 're a ll ll ll ll y END',\n",
       " '_ re a ll y _ END',\n",
       " 're a ll y y y y y END',\n",
       " 're a ll y 2 END',\n",
       " 's h o le END',\n",
       " 're a a a a a ll y END',\n",
       " 're e l y END',\n",
       " 're ll e END',\n",
       " 're a ll l y y y END',\n",
       " 's h o l END',\n",
       " 're e a ll y END',\n",
       " 're e e e e a ll y END',\n",
       " 're a ll ll ll l y END',\n",
       " 'r i ll y END',\n",
       " 're a ll y y y y END',\n",
       " 're a a a a ll y END',\n",
       " 're a a a ll y END',\n",
       " 'r i l i END',\n",
       " 're e e a ll y END',\n",
       " 're a a ll y END',\n",
       " 're a ll ll ll y END',\n",
       " 're e e e a ll y END',\n",
       " 're a ll y y y END',\n",
       " 'r i l y END',\n",
       " 's h o ll END',\n",
       " 're al i END',\n",
       " 're l i END',\n",
       " 're a ll ll l y END',\n",
       " 're ll y END',\n",
       " 're a ll i END',\n",
       " 're le END',\n",
       " 're a ll y y END',\n",
       " 're a ll ll y END',\n",
       " 're a ll l y END',\n",
       " 'r ll y END',\n",
       " 'g en u in e l y END',\n",
       " 're al y END',\n",
       " 're a ll y END',\n",
       " 'r l y END',\n",
       " 'al re d ay END',\n",
       " 'al re ay d END',\n",
       " 'f in al i END',\n",
       " 'of f is h END',\n",
       " 'al r a d y END',\n",
       " 'w o o d a END',\n",
       " 'o re d i END',\n",
       " 'al re a a d y END',\n",
       " 'al re a d y y y y y END',\n",
       " 'al re a d d y END',\n",
       " 'a le a d y END',\n",
       " 'al re ay END',\n",
       " 's u c es s f u ll y END',\n",
       " 'al re d i END',\n",
       " 'a re a d y END',\n",
       " 'al re a d i END',\n",
       " 'al re a d i i END',\n",
       " 'al re a d END',\n",
       " 'al re a d y y y END',\n",
       " 'a w re a d y END',\n",
       " 'al r d END',\n",
       " 'c u d a END',\n",
       " 'al re d y END',\n",
       " 'a ll re a d y END',\n",
       " 'al re a d y y END',\n",
       " 'al r d y END',\n",
       " 'p re v i ou s l y END',\n",
       " 'al re a d y END',\n",
       " 're c en t l y END',\n",
       " '- al m o st END',\n",
       " 'n e al y END',\n",
       " 'n e ar ll y END',\n",
       " 'al m 0 st END',\n",
       " 'a lo m o st END',\n",
       " 'a lo m st END',\n",
       " 'al m o st t END',\n",
       " 'al m s o t END',\n",
       " 'a m o st END',\n",
       " 'a ll m o st END',\n",
       " 'al m st END',\n",
       " 'a v er a g ing END',\n",
       " 'r ou g h l y END',\n",
       " 'v i r t u a ll y END',\n",
       " 'a p p r o x i m at e l y END',\n",
       " 'p r a c t i c a ll y END',\n",
       " 'al m o st END',\n",
       " 'n e ar l y END',\n",
       " 's i b b y END',\n",
       " 'c u r re n t y END',\n",
       " 'of f i c a i ll y END',\n",
       " 'of f c i a ll y END',\n",
       " '# b g g p l ay END',\n",
       " 'c u re n t l y END',\n",
       " 'b u s i l y END',\n",
       " 'of f i c al y END',\n",
       " 'of i c i a ll y END',\n",
       " 'c or d i a ll y END',\n",
       " '<URL- l i st en . g h e t to r a d i o . f m > END',\n",
       " '<URL- k a is er e g g . ch > END',\n",
       " 'h u c k le b er r i es END',\n",
       " 'h e is e END',\n",
       " '# re a d c a st END',\n",
       " 'p re s en t l y END',\n",
       " 'of f i c i al y END',\n",
       " '<URL- g o . n i k e . co m > END',\n",
       " 'of f i c a ll y END',\n",
       " 're p or t ed l y END',\n",
       " 'of f i c i a ll y END',\n",
       " 'c u r re n t l y END',\n",
       " 'f in a ll l y y END',\n",
       " 'f in a ll i END',\n",
       " 'f in a ll l y y y END',\n",
       " '# of f i c i a ll y END',\n",
       " 'f i i i in a ll y END',\n",
       " 'f n a ll y END',\n",
       " 'f in a ll y y y y y END',\n",
       " 'f i in a ll y END',\n",
       " '- f in a ll y END',\n",
       " 'b er l y END',\n",
       " 'f in a ll ll ll y END',\n",
       " '# th ing s i d i d o v er the s u m m er END',\n",
       " '<URL- m a p m y f it n es s . co m > END',\n",
       " 'f in a ll ll l y END',\n",
       " 'f in i a ll y END',\n",
       " 's n a c k f e ed END',\n",
       " 'f in a ll y y y y END',\n",
       " 'f in a ll ll y END',\n",
       " 'f i an ll y END',\n",
       " '<URL- m a p m y r i d e . co m > END',\n",
       " 'f in a ll y y y END',\n",
       " 's u c c es f u ll y END',\n",
       " 'f in a ll y y END',\n",
       " '# m y f it n es s p al END',\n",
       " 'f in n a ll y END',\n",
       " '<URL- m a p m y r u n . co m > END',\n",
       " 'f in a ll l y END',\n",
       " 're l u c t an t l y END',\n",
       " 'f in n al y END',\n",
       " '<URL- co or d . in f o > END',\n",
       " 'f in al y END',\n",
       " 'f in a ll y END',\n",
       " 's u c c es s f u ll y END',\n",
       " 'k n ow e st END',\n",
       " 'r a th r END',\n",
       " 'c an st END',\n",
       " '<URL- s u p er m ar k e t . co m > END',\n",
       " 'r a th a END',\n",
       " 'r a th er END',\n",
       " 's ha l t END',\n",
       " \"d on t ' c ha END\",\n",
       " 'i i on END',\n",
       " 'i m m o END',\n",
       " '4 + 4 END',\n",
       " 'i i b END',\n",
       " 'i d on t t END',\n",
       " 'b r in j al END',\n",
       " 'i d on END',\n",
       " 'the ll END',\n",
       " '2 i END',\n",
       " 'n u st END',\n",
       " 'a b t a END',\n",
       " 'le y s END',\n",
       " 'me + you END',\n",
       " 'le m m a END',\n",
       " 's h ou l d s END',\n",
       " 'w e ll i END',\n",
       " 'i / i i END',\n",
       " 'd i d st END',\n",
       " '1 i END',\n",
       " 'ch ar s e t END',\n",
       " 'u l d END',\n",
       " 'd / n END',\n",
       " 'í END',\n",
       " 'f . i . n . a . l . s . END',\n",
       " 'i ow n END',\n",
       " 'i i d END',\n",
       " 'n on - v i r g in END',\n",
       " 's k y ha w k END',\n",
       " 's k y l an e END',\n",
       " 'ch _ t y p e END',\n",
       " 'k en o t END',\n",
       " 'd in n y END',\n",
       " '# i d on t END',\n",
       " '- i i END',\n",
       " '# y a m a m a e v er END',\n",
       " '2 0 1 0 / 0 7 END',\n",
       " '2 0 1 0 / 0 5 END',\n",
       " 'c . l . a . s . s . END',\n",
       " '& i END',\n",
       " 'i f u END',\n",
       " 'f m t END',\n",
       " 'th at i END',\n",
       " 'le m i END',\n",
       " '# m y g o al f or 2 0 1 2 END',\n",
       " 'y u d END',\n",
       " 'e b u END',\n",
       " 'b o t t a END',\n",
       " 'm on e y - b a c k END',\n",
       " '1 9 t END',\n",
       " 'i 8 END',\n",
       " '# on l y f at p e o p le END',\n",
       " '# th ing s i a in t d on e y e t END',\n",
       " 'd on t ch u END',\n",
       " 's g e END',\n",
       " 'i f i END',\n",
       " 'i l d END',\n",
       " '# c on f u s ing th ing s g i r l s d o END',\n",
       " '_ i _ END',\n",
       " 'm u z END',\n",
       " 'c an i END',\n",
       " '# u r g i r l f r i en d e v er END',\n",
       " 'i - i - i END',\n",
       " '# on l y u g l y p e o p le END',\n",
       " '2 0 1 0 / 1 2 END',\n",
       " 'le t t s END',\n",
       " 'n e er END',\n",
       " '2 0 1 0 / 1 0 END',\n",
       " '2 0 1 0 / 0 4 END',\n",
       " 'c y a a END',\n",
       " 's on t END',\n",
       " '2 0 1 0 / 0 8 END',\n",
       " 'd on n END',\n",
       " '2 0 1 0 / 0 6 END',\n",
       " 'a p t - g e t END',\n",
       " 'u on END',\n",
       " 'd o an END',\n",
       " 'd o st END',\n",
       " '# on l y wh it e p e o p le END',\n",
       " 'i i i i END',\n",
       " '# th ing s b l a c k p e o p le d o END',\n",
       " 'i d w END',\n",
       " '2 + 2 END',\n",
       " 'in e END',\n",
       " 'ha st END',\n",
       " 'i d i d n t END',\n",
       " '1 + 1 END',\n",
       " 'h ed END',\n",
       " 'p r o v o k ing END',\n",
       " 'i d n t END',\n",
       " 'u l END',\n",
       " 'u m a END',\n",
       " 'w d END',\n",
       " 'u d END',\n",
       " 'i i i END',\n",
       " 'll END',\n",
       " 'i v END',\n",
       " 'i on END',\n",
       " 'i i END',\n",
       " 'i d END',\n",
       " 'p r a c t i c al y END',\n",
       " 'u s s u a ll y END',\n",
       " 'a c c i d en t i a ll y END',\n",
       " 's u d en l y END',\n",
       " 't e ar f u ll y END',\n",
       " 'u s u a ll l y END',\n",
       " 'n a i ve l y END',\n",
       " 're f le x i ve l y END',\n",
       " 'o p t i on a ll y END',\n",
       " 'l i k e 2 END',\n",
       " 'c on t in u o s l y END',\n",
       " 'u n w is e l y END',\n",
       " 'p r a c t i c l y END',\n",
       " 'at u a ll y END',\n",
       " 'a c t l y END',\n",
       " 'p u r p o s l y END',\n",
       " 's e c re t e l y END',\n",
       " 'h ar d le y END',\n",
       " 'a u to m at i c al y END',\n",
       " 'c on c e i v a b l y END',\n",
       " 'a b s en t m in d ed l y END',\n",
       " 'a c t u a ll i END',\n",
       " 'l it r a ll y END',\n",
       " 's u b c on c i ou s l y END',\n",
       " 'c on st an l y END',\n",
       " 'l it er l y END',\n",
       " 'd o in t END',\n",
       " 'm a k e m END',\n",
       " 's u p p o s e l y END',\n",
       " 'a c t u a ll y y END',\n",
       " 'a c t u l y END',\n",
       " 'g o an n a END',\n",
       " 'b as c i a ll y END',\n",
       " 'p r at i c a ll y END',\n",
       " 'i i ve END',\n",
       " 's u p p o s a b l y END',\n",
       " 'b as i c al y END',\n",
       " 'er r on e ou s l y END',\n",
       " 'f l at l y END',\n",
       " 'c as j END',\n",
       " 'le g it l y END',\n",
       " 'l it t er l y END',\n",
       " 'm u s s y END',\n",
       " 'or g in a ll y END',\n",
       " 'd on r END',\n",
       " 'in a d v er t an t l y END',\n",
       " 'a c t a ll y END',\n",
       " 'a c t u al i END',\n",
       " 'u s u s a ll y END',\n",
       " 'a c c u a ll y END',\n",
       " 'in t u it i ve l y END',\n",
       " 'a u to m at i c l y END',\n",
       " 'g r u d g ing l y END',\n",
       " 'be g r u d g ing l y END',\n",
       " 's c ar c e l y END',\n",
       " 'b ar l y END',\n",
       " 'l it t er al y END',\n",
       " 'b l at en t l y END',\n",
       " 'ha b it u a ll y END',\n",
       " 'or d in ar i l y END',\n",
       " 'a f f e c t i on at e l y END',\n",
       " 's n e a k i l y END',\n",
       " 'a c c i d en t al y END',\n",
       " 'n or m al y END',\n",
       " 's ing le h and ed l y END',\n",
       " 'co m p u l s i ve l y END',\n",
       " 's u b l i m in a ll y END',\n",
       " 'in v o l u n t ar i l y END',\n",
       " 'a c t u a ll l y END',\n",
       " 'g in e END',\n",
       " 'd e f in it i ve l y END',\n",
       " 'u s u al y END',\n",
       " 'l it er al y END',\n",
       " 'b r a ve l y END',\n",
       " 'a c c t u a ll y END',\n",
       " 'a c u a ll y END',\n",
       " 'b as i c l y END',\n",
       " 'ha f f END',\n",
       " 'in st in c t i ve l y END',\n",
       " 'u n c on s c i ou s l y END',\n",
       " 's ing le - h and ed l y END',\n",
       " 's l y l y END',\n",
       " 'a c t a u ll y END',\n",
       " 'd r u n k en l y END',\n",
       " 'a c u t a ll y END',\n",
       " 'f o o l is h l y END',\n",
       " 'be ar l y END',\n",
       " 'p u r p o s e f u ll y END',\n",
       " 'j o k ing l y END',\n",
       " 'r ou t in e l y END',\n",
       " 'k n ow ing l y END',\n",
       " 's u b c on s c i ou s l y END',\n",
       " 'u n k n ow ing l y END',\n",
       " 'a c t u ll y END',\n",
       " 'm i r a c u l ou s l y END',\n",
       " 'l it t er a ll y END',\n",
       " 'co ll e c t i ve l y END',\n",
       " 't r a d it i on a ll y END',\n",
       " 'in a d v er t en t l y END',\n",
       " 'm i st a k en l y END',\n",
       " 'v o l u n t ar i l y END',\n",
       " 'b l in d l y END',\n",
       " 'in d i re c t l y END',\n",
       " 's p on t an e ou s l y END',\n",
       " 'w i ll ing l y END',\n",
       " 'h er e b y END',\n",
       " 'g r a d u a ll y END',\n",
       " 'a c t u al y END',\n",
       " 'j es END',\n",
       " 'd e l i b er at e l y END',\n",
       " 'c on t in u ou s l y END',\n",
       " 's e l d o m END',\n",
       " 'in t en t i on a ll y END',\n",
       " 'p u r p o s e l y END',\n",
       " 'b ar le y END',\n",
       " 'in it i a ll y END',\n",
       " 'a c t i ve l y END',\n",
       " 'on t END',\n",
       " 'c as u a ll y END',\n",
       " 'es s en t i a ll y END',\n",
       " 'p r ou d l y END',\n",
       " 't y p i c a ll y END',\n",
       " 'a c c i d en t l y END',\n",
       " 'm a g i c a ll y END',\n",
       " 'a ll e g ed l y END',\n",
       " 's u p p o s ed l y END',\n",
       " 'or i g in a ll y END',\n",
       " 's e c re t l y END',\n",
       " 'g en er a ll y END',\n",
       " 'r a re l y END',\n",
       " 'a u to m at i c a ll y END',\n",
       " 'a c c i d en t a ll y END',\n",
       " 'r and o m l y END',\n",
       " 'n or m a ll y END',\n",
       " 'c on st an t l y END',\n",
       " 'h ar d l y END',\n",
       " 'b a re l y END',\n",
       " 'b as i c a ll y END',\n",
       " 'l it er a ll y END',\n",
       " 'a c t u a ll y END',\n",
       " 'u s u a ll y END',\n",
       " 's u d d en t l y END',\n",
       " '- al w ay s END',\n",
       " 'a lo s END',\n",
       " 'co in c i d en t l y END',\n",
       " 'p r ay er f u ll y END',\n",
       " 'd e m on b r u en END',\n",
       " 'd es p ar at e l y END',\n",
       " 'g i es END',\n",
       " 'd es p er at l y END',\n",
       " 'as lo END',\n",
       " 'al t er n at e l y END',\n",
       " 'be l at ed l y END',\n",
       " 'j x END',\n",
       " 's u b s e q u en t l y END',\n",
       " 's in c er l y END',\n",
       " 'h en c e f or th END',\n",
       " 'u l t i m at e l y END',\n",
       " 'd es p er at e l y END',\n",
       " 's in c er e l y END',\n",
       " 's u d d en l y END',\n",
       " 'al s o END',\n",
       " 'o b i ou s l y END',\n",
       " 'd e a d a z z END',\n",
       " 'e v i d en t a ll y END',\n",
       " 'to t a ll y y y END',\n",
       " 's r i ou s l y END',\n",
       " 'o b v i ou l s y END',\n",
       " 'o b v s l y END',\n",
       " 's er o i u s l y END',\n",
       " 'n e v er r r r r r r END',\n",
       " 's er is ou l y END',\n",
       " 'h on e st l y y END',\n",
       " 's r l s y END',\n",
       " 's er i ou s l y y y y END',\n",
       " 'l it er a ll l y END',\n",
       " 'o b v i o s l y END',\n",
       " 'o v i ou s l y END',\n",
       " 'g o t t c ha END',\n",
       " 'o b v z END',\n",
       " 'd / a END',\n",
       " 'w is h i END',\n",
       " 'g o t c ha a END',\n",
       " 'i i i i i i i i i END',\n",
       " '# j u st c a u s e w e co o l END',\n",
       " \"s or r y ' s END\",\n",
       " 'l i k e e e e e e END',\n",
       " 's h e e e e END',\n",
       " 'g o t ch y a END',\n",
       " 's r l y END',\n",
       " 'f er re al END',\n",
       " 's er i ou s l y y y END',\n",
       " 's i r i u s l y END',\n",
       " 'g e z END',\n",
       " 'n e v er r r r r r END',\n",
       " 'lo k e y END',\n",
       " 's u r le y END',\n",
       " 's er i ou s ll y END',\n",
       " 'h on es l t y END',\n",
       " 's er i u o s l y END',\n",
       " 'd e a d as s s END',\n",
       " 'l ow k e y y END',\n",
       " '- re a ll y END',\n",
       " 's er i u s l y END',\n",
       " 's er i ou l y END',\n",
       " 'be t ch u END',\n",
       " 's er ou s l y END',\n",
       " 's er z l y END',\n",
       " 'h i g h k e y END',\n",
       " 'n e v er r r r r END',\n",
       " 's er i o s l y END',\n",
       " 'l i k e e e e e END',\n",
       " 's er i ou l s y END',\n",
       " 's er i o s u l y END',\n",
       " 'p er s on al y END',\n",
       " 'u n d er st and a b l y END',\n",
       " 'u n n o END',\n",
       " 's er i ou s l y y END',\n",
       " 'g ed d it END',\n",
       " 'l i k e e e e END',\n",
       " 'the o re t i c a ll y END',\n",
       " 'd . a END',\n",
       " 're al i st i c a ll y END',\n",
       " 'o b v i END',\n",
       " 't r u th f u ll y END',\n",
       " 'o b v s END',\n",
       " 'be t c ha END',\n",
       " '# l ow k e y END',\n",
       " 'o b v END',\n",
       " ...]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preform_bpe(brown_df, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9888b25499797c4fb0fd4f13646b0c3c",
     "grade": false,
     "grade_id": "cell-7d1e49878db56df4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Jakie angielskie słowo jako pierwsze dostało swój własny token?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df4c7b8b5aa2b077eaa2d42429797139",
     "grade": true,
     "grade_id": "cell-acd48c77e2c1bcec",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd51e6fc0cd1d3b4d8b9e9a2fa1b0316",
     "grade": false,
     "grade_id": "cell-df60f5e5c6fe4ca0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Jakie są zalety korzystania z tokenizacji BPE w kontekście tworzenia reprezentacji (problem OOV, odnieś się do  k-gramów i n-gramów)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64306e36b58f1eee12c8bb339123e105",
     "grade": true,
     "grade_id": "cell-006ef6fd3e397206",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Możemy zaobserwować następujące zalety:\n",
    "* a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2 - klasyfikacja (15 pkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy kod powinien wczytać i ztokenizować zbiór danych dot. analizy wydźwięku. Jeśli nie masz biblioteki `nltk` musisz ją zainstalować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import DataSet\n",
    "training_set = DataSet(['tweets.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajdziesz przykład odczytu jednego tweeta z obiektu DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in training_set.tweets:\n",
    "    print(i.text)\n",
    "    print(i.tokens)\n",
    "    print(i.clazz)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Systemy IL często pracują z bardzo dużą liczbą cech, które są rzadkie np. cechy Bag-Of-Words, cechy n-gramowe itd. Powoduje to że klasyczna macierz przykłady uczące na cechy rośnie do bardzo dużych rozmiarów nawet dla małych zbiorów uczących (w sensie liczby przykładów). Ponadto samo przechowywanie w pamięci słownika mapującego konkretne słowa/n-gramy na indeksy kolumn macierzy może być bardzo kosztowne pamięciowo przy dużych rozmiarach słownika.\n",
    "\n",
    "Istnieje jednak technika, która pozwala nam na ominięcie tej przeszkody: haszowanie cech. Opis tej techniki znajdziesz na stronie:  https://en.wikipedia.org/wiki/Feature_hashing Jest ona też implementowana w obiekcie `sklearn.feature_extraction.FeatureHasher`. Zapoznaj się z opisem techniki i wykonaj poniższe polecenia.\n",
    "\n",
    "- Wykorzystując haszowanie cech wytrenuj wybrany klasyfikator na zbiorze uczącym dla cech Bag-of-words (możesz też spróbować cechy n-gramowe). Możesz wykorzystać gotową tokenizację we właściwości `.tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac05ad71ee90b1c800030849c5321cb7",
     "grade": true,
     "grade_id": "cell-f6cfe39258fbec51",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd6bcaf8dae7184b60bd9a8adadd85d8",
     "grade": false,
     "grade_id": "cell-1caf16c401c91ef2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Stwórz wykres zależności wybranej miary klasyfikacji od wymiarów macierzy danych (chodzi o liczbę cech do których haszujemy cechy oryginalne). Wystarczy przetestować kilka (>=4) wybranych wartości na skali logarytmicznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bd253bac561b269cff3a3dceadc70f0",
     "grade": true,
     "grade_id": "cell-8076c16242981ae9",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82f3f52a6fe2a10a300b5d45101b32b5",
     "grade": false,
     "grade_id": "cell-eab7c2a5f0251ff4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    " - Obserwując stworzony wykres - skomentuj. Jak dużo jakości klasyfikacji się traci (albo zyskuje?) korzystając z mniejszej liczby haszowanych cech? Często klasyfikatory bardzo dobrze działają nawet przy liczbie haszowanych cech dla których na pewno istnieją konflikty cech oryginalnych - jak myślisz dlaczego? (Pomyśl o interpretacji takich skonfliktowanych cech)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed30f2d487da41cf1a92ffb63195d621",
     "grade": true,
     "grade_id": "cell-2caea1821af5d8aa",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20139da166319b49eea5cc7e984fc08e",
     "grade": false,
     "grade_id": "cell-0d86672dbabbf54d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    " - W poprzednim zadaniu wczytałeś wynik grupowania Browna do pamięci. Wytrenuj klasyfikator na reprezentacji ,,Bag-of-clusters'' tj. w kolumnach zamiast słów/n-gramów będziesz miał grupy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b13c0457af5dab17e12780eafb1c5ac4",
     "grade": true,
     "grade_id": "cell-55264f6fe514d007",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e47a053ebc12ac2fd97d9c11187da9b",
     "grade": false,
     "grade_id": "cell-493071698fc0205e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- Podsumuj eksperymenty: poznałeś dwie możliwości ograniczenia liczby cech - zastąpienie słów ich grupami i haszowanie cech. Jakie są wady i zalety obydwu podejść?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b80ace505afba9b12fd5d3896a9046ef",
     "grade": true,
     "grade_id": "cell-4508400659f7243e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
